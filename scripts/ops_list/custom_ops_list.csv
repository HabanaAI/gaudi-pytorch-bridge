../../habana_kernels/kernels_register.cpp:2582;       hccl; allgather_out;                                      allgather_out(Tensor input_tensor, int64_t comm_id, Tensor(a!) output_tensor) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2576;       hccl; allreduce_;                                         allreduce_(Tensor(a!) tensor, uint8_t reduceOp, int64_t comm_id) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2580;       hccl; alltoall_out;                                       alltoall_out(Tensor input_tensor, int64_t comm_id,int[]  outputSplitSizes, int[] inputSplitSizes, Tensor(a!) output_tensor) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2574;       hccl; broadcast_;                                         broadcast_(Tensor(a!) tensor, int root_rank, int64_t comm_id) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2588;       hccl; recv_;                                              recv_(Tensor(a!) tensor,  int64_t src_rank,  int64_t tag, int64_t comm_id) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2578;       hccl; reduce_;                                            reduce_(Tensor(a!) tensor, int64_t dst_rank, uint8_t reduceOp, int64_t comm_id) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2584;       hccl; reduce_scatter_out;                                 reduce_scatter_out(Tensor input_tensor, uint8_t reduceOp, int64_t comm_id, Tensor(a!) output_tensor) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2586;       hccl; send_;                                              send_(Tensor(a!) tensor,  int64_t dst_rank,  int64_t tag, int64_t comm_id) -> Tensor(a!);
../../habana_eager/ops/copy_from.cpp:441;             hpu;  _copy_from;                                         _copy_from(Tensor self, Tensor dst) -> Tensor;
../../generated/backend/hpu_op0.cpp:1088;             hpu;  _fused_dropout;                                     _fused_dropout(Tensor self, float p, Tensor? seed) -> (Tensor, Tensor);
../../habana_eager/ops/index_put.cpp:496;             hpu;  _index_put_impl_bool_eager;                         _index_put_impl_bool_eager(Tensor self, Tensor[] indices, Tensor value, bool accumulate=False) -> Tensor;
../../habana_eager/ops/index_put.cpp:492;             hpu;  _index_put_impl_eager;                              _index_put_impl_eager(Tensor self, Tensor[] indices, Tensor value, bool accumulate=False) -> Tensor;
../../habana_kernels/kernels_register.cpp:2232;       hpu;  _unique;                                            _unique(Tensor self, bool sorted, bool return_inverse) -> (Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2234;       hpu;  _unique2;                                           _unique2(Tensor self, bool sorted, bool return_inverse, bool return_counts) -> (Tensor, Tensor);
../../habana_eager/ops/unique2.cpp:137;               hpu;  _unique2_eager;                                     _unique2_eager(Tensor self, bool sorted, bool return_inverse, bool return_counts) -> (Tensor, Tensor, Tensor, Tensor);
../../habana_eager/ops/unique.cpp:91;                 hpu;  _unique_eager;                                      _unique_eager(Tensor self, bool sorted, bool return_inverse) -> (Tensor, Tensor, Tensor);
../../generated/backend/hpu_op6.cpp:1155;             hpu;  addcdiv;                                            addcdiv(Tensor self, Tensor tensor1, Tensor tensor2, *, Tensor? value=None) -> Tensor;
../../generated/backend/hpu_op6.cpp:1154;             hpu;  addcdiv.out;                                        addcdiv.out(Tensor self, Tensor tensor1, Tensor tensor2, *, Tensor? value=None, Tensor(a!) out) -> Tensor(a!);
../../generated/backend/hpu_op6.cpp:1156;             hpu;  addcdiv_;                                           addcdiv_(Tensor(a!) self, Tensor tensor1, Tensor tensor2, *, Tensor? value=None) -> Tensor(a!);
../../generated/backend/hpu_op6.cpp:1152;             hpu;  addcmul;                                            addcmul(Tensor self, Tensor tensor1, Tensor tensor2, *, Tensor? value=None) -> Tensor;
../../generated/backend/hpu_op6.cpp:1151;             hpu;  addcmul.out;                                        addcmul.out(Tensor self, Tensor tensor1, Tensor tensor2, *, Tensor? value=None, Tensor(a!) out) -> Tensor(a!);
../../generated/backend/hpu_op6.cpp:1153;             hpu;  addcmul_;                                           addcmul_(Tensor(a!) self, Tensor tensor1, Tensor tensor2, *, Tensor? value=None) -> Tensor(a!);
../../generated/backend/hpu_op0.cpp:1091;             hpu;  arange.start_out;                                   arange.start_out(Scalar start, Scalar end, Scalar step, *, Tensor? h2d_tensor=None, Tensor? shape_tensor=None, Tensor(a!) out) -> Tensor(a!);
../../generated/backend/hpu_op0.cpp:1090;             hpu;  arange.start_step;                                  arange.start_step(Tensor h2d_tensor, Tensor shape_tensor,*, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2301;       hpu;  as_strided_layout;                                  as_strided_layout(Tensor self, int[] size) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2258;       hpu;  as_strided_lazy_;                                   as_strided_lazy_(Tensor self, int[] size, int[] stride, int offset, bool can_replace) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2260;       hpu;  as_strided_lazy_cl_;                                as_strided_lazy_cl_(Tensor self, int[] size, int[] stride, int offset, bool can_replace) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2226;       hpu;  batched_nms;                                        batched_nms(Tensor boxes, Tensor scores, Tensor indexes, float iou_threshold, Tensor shape_tensor1, Tensor shape_tensor2, int max_classes) -> (Tensor, Tensor);
../../generated/backend/hpu_op0.cpp:1092;             hpu;  bernoulli;                                          bernoulli(Tensor self, *, Tensor? seed=None) -> Tensor;
../../generated/backend/hpu_op9.cpp:1220;             hpu;  bernoulli.float_out;                                bernoulli.float_out(Tensor self, Tensor p, *, Tensor? seed=None, Tensor(a!) out) -> Tensor(a!);
../../generated/backend/hpu_op0.cpp:1093;             hpu;  bernoulli.out;                                      bernoulli.out(Tensor self, *, Tensor? seed=None, Tensor(a!) out) -> Tensor(a!);
../../generated/backend/hpu_op0.cpp:1094;             hpu;  bernoulli_.Tensor;                                  bernoulli_.Tensor(Tensor(a!) self, Tensor p, *, Tensor? seed=None) -> Tensor(a!);
../../generated/backend/hpu_op0.cpp:1095;             hpu;  bernoulli_.float;                                   bernoulli_.float(Tensor(a!) self, Tensor p, *, Tensor? seed=None) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2198;       hpu;  cast;                                               cast(Tensor self, Scalar type) -> Tensor(a);
../../habana_kernels/kernels_register.cpp:2175;       hpu;  cat;                                                cat(Tensor[] tensors, int dim, Tensor out_shape) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1659; hpu;  control_edge_;                                      control_edge_(Tensor(a) self)-> Tensor(a);
../../habana_kernels/kernels_register.cpp:2246;       hpu;  control_edge_;                                      control_edge_(Tensor(a) self)-> Tensor(a);
../../habana_kernels/kernels_register.cpp:2245;       hpu;  control_edge_other_;                                control_edge_other_(Tensor self, Tensor(a) other) -> Tensor(a);
../../habana_kernels/kernels_register.cpp:2189;       hpu;  diag_out;                                           diag_out(Tensor self, int diagonal, Tensor(a!) out) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2184;       hpu;  div_out;                                            div_out(Tensor self, Tensor other, Tensor(a!) out) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2200;       hpu;  embedding_bag_sum;                                  embedding_bag_sum(Tensor input, Tensor indices, Tensor offsets, Tensor valid_count, int kernel_mode) -> Tensor;
../../habana_kernels/kernels_register.cpp:2202;       hpu;  embedding_bag_sum_bwd_out;                          embedding_bag_sum_bwd_out(Tensor(a!) out, Tensor input, Tensor indices_bwd, Tensor offsets_bwd, Tensor valid_count_bwd, int kernel_mode) -> Tensor(a!);
../../generated/backend/hpu_op9.cpp:1222;             hpu;  exponential;                                        exponential(Tensor self, float lambd=1.0, *, Tensor seed) -> Tensor;
../../generated/backend/hpu_op9.cpp:1221;             hpu;  exponential.out;                                    exponential.out(Tensor self, float lambd=1.0, *, Tensor seed, Tensor(a!) out) -> Tensor(a!);
../../generated/backend/hpu_op5.cpp:1253;             hpu;  exponential_;                                       exponential_(Tensor(a!) self, float lambd=1.0, *, Tensor seed) -> Tensor(a!);
../../habana_kernels/norm_kernels.cpp:2007;           hpu;  fused_norm_;                                        fused_norm_(Tensor(a!)[] grad, Tensor max_norm, float norm_type) -> Tensor;
../../habana_kernels/norm_kernels.cpp:2009;           hpu;  fused_norm_lazy;                                    fused_norm_lazy(Tensor(a!)[] grad, Tensor max_norm, float norm_type) -> Tensor;
../../habana_kernels/kernels_register.cpp:2238;       hpu;  gather_elements;                                    gather_elements(Tensor self, Tensor index, Tensor? opt, int64_t dim_, bool sorted) -> Tensor;
../../generated/backend/hpu_op9.cpp:1223;             hpu;  geometric.out;                                      geometric.out(Tensor self, float p, Tensor seed, Tensor(a!) out) -> Tensor(a!);
../../generated/backend/hpu_op5.cpp:1254;             hpu;  geometric_;                                         geometric_(Tensor(a!) self, float p, Tensor seed) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2204;       hpu;  habanaOptimizerFusedAdagrad;                        habanaOptimizerFusedAdagrad(Tensor[] gradients, Tensor(a!)[] weights_in, Tensor(b!)[] variances_in, Tensor epoch_num, Tensor(c!) learning_rate, float wd, float lrd, float eps) -> ();
../../habana_kernels/kernels_register.cpp:2206;       hpu;  habanaOptimizerFusedSGD;                            habanaOptimizerFusedSGD(Tensor[] gradients, Tensor(a!)[] weights_in, Tensor(b!) learning_rate, float wd, float mom, float damp, bool nesterov) -> ();
../../habana_kernels/kernels_register.cpp:2220;       hpu;  habanaOptimizerLars;                                habanaOptimizerLars(Tensor[] params, Tensor(a!)[] grads, Tensor lr_t, int[] skip_masks, float eeta, float weight_decay, float eps) -> ();
../../habana_kernels/kernels_register.cpp:2197;       hpu;  habanaOptimizerSparseAdagrad;                       habanaOptimizerSparseAdagrad(Tensor gradients, Tensor(a!) weights_in, Tensor(b!) moments_in, Tensor indices, Tensor learning_rate, Tensor valid_count_tensor) -> (Tensor(a!), Tensor(b!));
../../habana_kernels/kernels_register.cpp:2195;       hpu;  habanaOptimizerSparseSgd;                           habanaOptimizerSparseSgd(Tensor gradients, Tensor(a!) weights_in, Tensor(b!) moments_in, Tensor indices, Tensor learning_rate, Tensor valid_count_tensor, float mom, bool nesterov) -> (Tensor(a!), Tensor(b!));
../../habana_kernels/kernels_register.cpp:2193;       hpu;  habana_d2d_memcpy;                                  habana_d2d_memcpy(Tensor self) -> Tensor;
../../habana_kernels/kernels_register.cpp:2186;       hpu;  habana_d2d_memcpy_other;                            habana_d2d_memcpy_other(Tensor s, Tensor(a!) d) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2224;       hpu;  habana_nms;                                         habana_nms(Tensor boxes, Tensor scores, float iou_threshold, float score_threshold) -> (Tensor, Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1812; hpu;  hpu::accumulate_grads_;                             hpu::accumulate_grads_(Tensor[] variables, Tensor[] new_grads) -> ();
../../habana_kernels/kernels_register.cpp:2331;       hpu;  hpu::add.Scalar;                                    hpu::add.Scalar(Tensor self, Scalar other, Scalar alpha) -> Tensor;
../../habana_kernels/kernels_register.cpp:2330;       hpu;  hpu::add.Tensor;                                    hpu::add.Tensor(Tensor self, Tensor other, Scalar alpha) -> Tensor;
../../habana_kernels/kernels_register.cpp:2335;       hpu;  hpu::add_.Scalar;                                   hpu::add_.Scalar(Tensor(a) self, Scalar other, Scalar alpha) -> Tensor(a);
../../habana_kernels/kernels_register.cpp:2333;       hpu;  hpu::add_.Tensor;                                   hpu::add_.Tensor(Tensor(a) self, Tensor other, Scalar alpha) -> Tensor(a);
../../habana_eager/eager_custom_op_register.cpp:1661; hpu;  hpu::cast_from_fp8;                                 hpu::cast_from_fp8(Tensor input, Tensor? scale, ScalarType out_dtype, int[]? scale_shape=None) -> Tensor;
../../habana_kernels/kernels_register.cpp:2356;       hpu;  hpu::cast_from_fp8;                                 hpu::cast_from_fp8(Tensor input, Tensor? scale, ScalarType out_dtype, int[]? scale_shape=None) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1663; hpu;  hpu::cast_from_fp8.scalar;                          hpu::cast_from_fp8.scalar(Tensor input, float scale, ScalarType out_dtype, int[]? scale_shape=None) -> Tensor;
../../habana_kernels/kernels_register.cpp:2358;       hpu;  hpu::cast_from_fp8.scalar;                          hpu::cast_from_fp8.scalar(Tensor input, float scale, ScalarType out_dtype, int[]? scale_shape=None) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1665; hpu;  hpu::cast_from_fp8.scalar_list;                     hpu::cast_from_fp8.scalar_list(Tensor input, float[] scale, ScalarType out_dtype, int[]? scale_shape=None) -> Tensor;
../../habana_kernels/kernels_register.cpp:2360;       hpu;  hpu::cast_from_fp8.scalar_list;                     hpu::cast_from_fp8.scalar_list(Tensor input, float[] scale, ScalarType out_dtype, int[]? scale_shape=None) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1667; hpu;  hpu::cast_to_fp8;                                   hpu::cast_to_fp8(Tensor input, Tensor? scale, bool stochastic_rounding, Tensor(a!) out, Tensor(b!) amax) -> (Tensor(a!), Tensor(b!));
../../habana_kernels/kernels_register.cpp:2340;       hpu;  hpu::cast_to_fp8;                                   hpu::cast_to_fp8(Tensor input, Tensor? scale, bool stochastic_rounding, Tensor(a!) out, Tensor(b!) amax) -> (Tensor(a!), Tensor(b!));
../../habana_eager/eager_custom_op_register.cpp:1675; hpu;  hpu::cast_to_fp8_hybrid;                            hpu::cast_to_fp8_hybrid(Tensor input, Tensor? scale_152=None, Tensor? scale_143=None, bool stochastic_rounding=False, bool is_amax=False) -> (Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2348;       hpu;  hpu::cast_to_fp8_hybrid;                            hpu::cast_to_fp8_hybrid(Tensor input, Tensor? scale_152=None, Tensor? scale_143=None, bool stochastic_rounding=False, bool is_amax=False) -> (Tensor, Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1669; hpu;  hpu::cast_to_fp8_v2;                                hpu::cast_to_fp8_v2(Tensor input, Tensor? scale=None, bool stochastic_rounding=False, bool is_amax=False, ScalarType? dtype=None, int[]? scale_shape=None) -> (Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2342;       hpu;  hpu::cast_to_fp8_v2;                                hpu::cast_to_fp8_v2(Tensor input, Tensor? scale=None, bool stochastic_rounding=False, bool is_amax=False, ScalarType? dtype=None, int[]? scale_shape=None) -> (Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1671; hpu;  hpu::cast_to_fp8_v2.scalar;                         hpu::cast_to_fp8_v2.scalar(Tensor input, float scale, bool stochastic_rounding=False, bool is_amax=False, ScalarType? dtype=None, int[]? scale_shape=None) -> (Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2344;       hpu;  hpu::cast_to_fp8_v2.scalar;                         hpu::cast_to_fp8_v2.scalar(Tensor input, float scale, bool stochastic_rounding=False, bool is_amax=False, ScalarType? dtype=None, int[]? scale_shape=None) -> (Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1673; hpu;  hpu::cast_to_fp8_v2.scalar_list;                    hpu::cast_to_fp8_v2.scalar_list(Tensor input, float[] scale, bool stochastic_rounding=False, bool is_amax=False, ScalarType? dtype=None, int[]? scale_shape=None) -> (Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2346;       hpu;  hpu::cast_to_fp8_v2.scalar_list;                    hpu::cast_to_fp8_v2.scalar_list(Tensor input, float[] scale, bool stochastic_rounding=False, bool is_amax=False, ScalarType? dtype=None, int[]? scale_shape=None) -> (Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2325;       hpu;  hpu::constant_pad_nd;                               hpu::constant_pad_nd(Tensor self, int[] pad_tensor, Scalar value) -> Tensor;
../../habana_kernels/kernels_register.cpp:2323;       hpu;  hpu::constant_pad_nd_ht;                            hpu::constant_pad_nd_ht(Tensor self, Tensor pad_tensor, Tensor output_shape_tensor, Scalar value) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1677; hpu;  hpu::conv2d_fp8;                                    hpu::conv2d_fp8(Tensor input, Tensor weight, Tensor? bias=None, int[2] stride=1, int[2] padding=0, int[2] dilation=1, int groups=1, ScalarType? out_dtype=None, Tensor? scale_input=None, Tensor? scale_weight=None) -> Tensor;
../../habana_kernels/kernels_register.cpp:2469;       hpu;  hpu::conv2d_fp8;                                    hpu::conv2d_fp8(Tensor input, Tensor weight, Tensor? bias=None, int[2] stride=1, int[2] padding=0, int[2] dilation=1, int groups=1, ScalarType? out_dtype=None, Tensor? scale_input=None, Tensor? scale_weight=None) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1679; hpu;  hpu::conv2d_fp8.scalar;                             hpu::conv2d_fp8.scalar(Tensor input, Tensor weight, Tensor? bias=None, int[2] stride=1, int[2] padding=0, int[2] dilation=1, int groups=1, ScalarType? out_dtype=None, float scale_input=1.0, float scale_weight=1.0) -> Tensor;
../../habana_kernels/kernels_register.cpp:2471;       hpu;  hpu::conv2d_fp8.scalar;                             hpu::conv2d_fp8.scalar(Tensor input, Tensor weight, Tensor? bias=None, int[2] stride=1, int[2] padding=0, int[2] dilation=1, int groups=1, ScalarType? out_dtype=None, float scale_input=1.0, float scale_weight=1.0) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1751; hpu;  hpu::ctc_loss_custom;                               hpu::ctc_loss_custom(Tensor log_probs, Tensor targets, Tensor input_lengths, Tensor target_lengths, int blank, int reduction, bool zero_infinity) -> (Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2416;       hpu;  hpu::ctc_loss_custom;                               hpu::ctc_loss_custom(Tensor log_probs, Tensor targets, Tensor input_lengths, Tensor target_lengths, int blank, int reduction, bool zero_infinity) -> (Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1753; hpu;  hpu::ctc_loss_custom_backward;                      hpu::ctc_loss_custom_backward(Tensor grad, Tensor log_probs, Tensor targets, Tensor input_lengths, Tensor target_lengths, Tensor neg_log_likelihood, Tensor log_alpha, int blank, int reduction, bool zero_infinity) -> Tensor;
../../habana_kernels/kernels_register.cpp:2418;       hpu;  hpu::ctc_loss_custom_backward;                      hpu::ctc_loss_custom_backward(Tensor grad, Tensor log_probs, Tensor targets, Tensor input_lengths, Tensor target_lengths, Tensor neg_log_likelihood, Tensor log_alpha, int blank, int reduction, bool zero_infinity) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1813; hpu;  hpu::custom_foreach_add_;                           hpu::custom_foreach_add_(Tensor(a!)[] self, Tensor[] other) -> ();
../../habana_eager/eager_custom_op_register.cpp:1680; hpu;  hpu::custom_softmax;                                hpu::custom_softmax(Tensor input, int flavor) -> Tensor;
../../habana_kernels/kernels_register.cpp:2404;       hpu;  hpu::custom_softmax;                                hpu::custom_softmax(Tensor input, int flavor) -> Tensor;
../../habana_kernels/kernels_register.cpp:2318;       hpu;  hpu::expand;                                        hpu::expand(Tensor(a) self, int[] sizes, *, bool implicit=False) -> Tensor(a);
../../habana_kernels/kernels_register.cpp:2320;       hpu;  hpu::expand_ds;                                     hpu::expand_ds(Tensor(a) self, Tensor shape, *, bool implicit=False) -> Tensor(a);
../../habana_eager/eager_custom_op_register.cpp:1682; hpu;  hpu::fp8_bgrad_dgelu;                               hpu::fp8_bgrad_dgelu(Tensor grad, Tensor input, Tensor? scale=None, Tensor? retain=None, bool stochastic_rounding=False, bool is_amax=False, ScalarType? dtype=None) -> (Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2368;       hpu;  hpu::fp8_bgrad_dgelu;                               hpu::fp8_bgrad_dgelu(Tensor grad, Tensor input, Tensor? scale=None, Tensor? retain=None, bool stochastic_rounding=False, bool is_amax=False, ScalarType? dtype=None) -> (Tensor, Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1684; hpu;  hpu::fp8_cast_transpose;                            hpu::fp8_cast_transpose(Tensor input, Tensor? scale, bool stochastic_rounding, Tensor(a!) out, Tensor(b!) transposed, Tensor(c!) amax) -> (Tensor(a!), Tensor(b!), Tensor(c!));
../../habana_kernels/kernels_register.cpp:2350;       hpu;  hpu::fp8_cast_transpose;                            hpu::fp8_cast_transpose(Tensor input, Tensor? scale, bool stochastic_rounding, Tensor(a!) out, Tensor(b!) transposed, Tensor(c!) amax) -> (Tensor(a!), Tensor(b!), Tensor(c!));
../../habana_eager/eager_custom_op_register.cpp:1686; hpu;  hpu::fp8_cast_transpose_bgrad;                      hpu::fp8_cast_transpose_bgrad(Tensor input, Tensor? scale, bool stochastic_rounding, Tensor(a!) out, Tensor(b!) transposed, Tensor(c!) bgrad, Tensor(d!) amax) -> (Tensor(a!), Tensor(b!), Tensor(c!), Tensor(d!));
../../habana_kernels/kernels_register.cpp:2352;       hpu;  hpu::fp8_cast_transpose_bgrad;                      hpu::fp8_cast_transpose_bgrad(Tensor input, Tensor? scale, bool stochastic_rounding, Tensor(a!) out, Tensor(b!) transposed, Tensor(c!) bgrad, Tensor(d!) amax) -> (Tensor(a!), Tensor(b!), Tensor(c!), Tensor(d!));
../../habana_eager/eager_custom_op_register.cpp:1688; hpu;  hpu::fp8_cast_transpose_bgrad_dgelu;                hpu::fp8_cast_transpose_bgrad_dgelu(Tensor grad, Tensor input, Tensor? scale, Tensor? retain, bool stochastic_rounding, Tensor(a!) out, Tensor(b!) transposed, Tensor(c!) bgrad, Tensor(d!) amax) -> (Tensor(a!), Tensor(b!), Tensor(c!), Tensor(d!));
../../habana_kernels/kernels_register.cpp:2354;       hpu;  hpu::fp8_cast_transpose_bgrad_dgelu;                hpu::fp8_cast_transpose_bgrad_dgelu(Tensor grad, Tensor input, Tensor? scale, Tensor? retain, bool stochastic_rounding, Tensor(a!) out, Tensor(b!) transposed, Tensor(c!) bgrad, Tensor(d!) amax) -> (Tensor(a!), Tensor(b!), Tensor(c!), Tensor(d!));
../../habana_eager/eager_custom_op_register.cpp:1689; hpu;  hpu::fp8_copy_;                                     hpu::fp8_copy_(Tensor(a!) self, Tensor src) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2453;       hpu;  hpu::fp8_copy_;                                     hpu::fp8_copy_(Tensor(a!) self, Tensor src) -> Tensor(a!);
../../habana_eager/eager_custom_op_register.cpp:1691; hpu;  hpu::fp8_dropout;                                   hpu::fp8_dropout(Tensor input, float p, Tensor? scale=None, bool stochastic_rounding=False, bool is_amax=False, ScalarType? dtype=None) -> (Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2362;       hpu;  hpu::fp8_dropout;                                   hpu::fp8_dropout(Tensor input, float p, Tensor? scale=None, bool stochastic_rounding=False, bool is_amax=False, ScalarType? dtype=None) -> (Tensor, Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1693; hpu;  hpu::fp8_fast_softmax;                              hpu::fp8_fast_softmax(Tensor input, Tensor mask, Tensor? scale, float softmax_scale, bool stochastic_rounding, bool is_amax, ScalarType? dtype=None) -> (Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2370;       hpu;  hpu::fp8_fast_softmax;                              hpu::fp8_fast_softmax(Tensor input, Tensor mask, Tensor? scale, float softmax_scale, bool stochastic_rounding, bool is_amax, ScalarType? dtype=None) -> (Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1695; hpu;  hpu::fp8_gelu;                                      hpu::fp8_gelu(Tensor input, Tensor? scale, bool stochastic_rounding, Tensor(a!) out, Tensor(b!) retain, Tensor(c!) amax) -> (Tensor(a!), Tensor(b!), Tensor(c!));
../../habana_kernels/kernels_register.cpp:2364;       hpu;  hpu::fp8_gelu;                                      hpu::fp8_gelu(Tensor input, Tensor? scale, bool stochastic_rounding, Tensor(a!) out, Tensor(b!) retain, Tensor(c!) amax) -> (Tensor(a!), Tensor(b!), Tensor(c!));
../../habana_eager/eager_custom_op_register.cpp:1697; hpu;  hpu::fp8_gelu_v2;                                   hpu::fp8_gelu_v2(Tensor input, Tensor? scale=None, bool stochastic_rounding=False, bool is_amax=False, ScalarType? dtype=None) -> (Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2366;       hpu;  hpu::fp8_gelu_v2;                                   hpu::fp8_gelu_v2(Tensor input, Tensor? scale=None, bool stochastic_rounding=False, bool is_amax=False, ScalarType? dtype=None) -> (Tensor, Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1699; hpu;  hpu::fp8_gemm;                                      hpu::fp8_gemm(Tensor A, bool trans_A, Tensor B, bool trans_B, Tensor D, ScalarType out_dtype, Tensor? A_scale_inv, Tensor? B_scale_inv, Tensor? bias, bool accumulate, Tensor(a!) out) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2374;       hpu;  hpu::fp8_gemm;                                      hpu::fp8_gemm(Tensor A, bool trans_A, Tensor B, bool trans_B, Tensor D, ScalarType out_dtype, Tensor? A_scale_inv, Tensor? B_scale_inv, Tensor? bias, bool accumulate, Tensor(a!) out) -> Tensor(a!);
../../habana_eager/eager_custom_op_register.cpp:1701; hpu;  hpu::fp8_gemm_v2;                                   hpu::fp8_gemm_v2(Tensor A, bool trans_A, Tensor B, bool trans_B, Tensor? D, ScalarType out_dtype, Tensor? A_scale_inv=None, Tensor? B_scale_inv=None, Tensor? bias=None, bool accumulate=False, int[]? B_scale_shape=None) -> Tensor;
../../habana_kernels/kernels_register.cpp:2376;       hpu;  hpu::fp8_gemm_v2;                                   hpu::fp8_gemm_v2(Tensor A, bool trans_A, Tensor B, bool trans_B, Tensor? D, ScalarType out_dtype, Tensor? A_scale_inv=None, Tensor? B_scale_inv=None, Tensor? bias=None, bool accumulate=False, int[]? B_scale_shape=None) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1703; hpu;  hpu::fp8_gemm_v2.scalar;                            hpu::fp8_gemm_v2.scalar(Tensor A, bool trans_A, Tensor B, bool trans_B, Tensor? D, ScalarType out_dtype, float A_scale_inv, float B_scale_inv, Tensor? bias=None, bool accumulate=False, int[]? B_scale_shape=None) -> Tensor;
../../habana_kernels/kernels_register.cpp:2378;       hpu;  hpu::fp8_gemm_v2.scalar;                            hpu::fp8_gemm_v2.scalar(Tensor A, bool trans_A, Tensor B, bool trans_B, Tensor? D, ScalarType out_dtype, float A_scale_inv, float B_scale_inv, Tensor? bias=None, bool accumulate=False, int[]? B_scale_shape=None) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1705; hpu;  hpu::fp8_gemm_v2.scalar_list;                       hpu::fp8_gemm_v2.scalar_list(Tensor A, bool trans_A, Tensor B, bool trans_B, Tensor? D, ScalarType out_dtype, float[] A_scale_inv, float[] B_scale_inv, Tensor? bias=None, bool accumulate=False, int[]? B_scale_shape=None) -> Tensor;
../../habana_kernels/kernels_register.cpp:2380;       hpu;  hpu::fp8_gemm_v2.scalar_list;                       hpu::fp8_gemm_v2.scalar_list(Tensor A, bool trans_A, Tensor B, bool trans_B, Tensor? D, ScalarType out_dtype, float[] A_scale_inv, float[] B_scale_inv, Tensor? bias=None, bool accumulate=False, int[]? B_scale_shape=None) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1707; hpu;  hpu::fp8_index_copy_;                               hpu::fp8_index_copy_(Tensor(a!) self, int dim, Tensor index, Tensor source) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2459;       hpu;  hpu::fp8_index_copy_;                               hpu::fp8_index_copy_(Tensor(a!) self, int dim, Tensor index, Tensor source) -> Tensor(a!);
../../habana_eager/eager_custom_op_register.cpp:1709; hpu;  hpu::fp8_index_select_v2;                           hpu::fp8_index_select_v2(Tensor self, int dim, Tensor index) -> Tensor;
../../habana_kernels/kernels_register.cpp:2462;       hpu;  hpu::fp8_index_select_v2;                           hpu::fp8_index_select_v2(Tensor self, int dim, Tensor index) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1711; hpu;  hpu::fp8_kv_reorder_;                               hpu::fp8_kv_reorder_(Tensor(a!) self, Tensor start, Tensor end, Tensor beam_idx) -> (Tensor(a!));
../../habana_kernels/kernels_register.cpp:2455;       hpu;  hpu::fp8_kv_reorder_;                               hpu::fp8_kv_reorder_(Tensor(a!) self, Tensor start, Tensor end, Tensor beam_idx) -> (Tensor(a!));
../../habana_eager/eager_custom_op_register.cpp:1713; hpu;  hpu::fp8_layernorm;                                 hpu::fp8_layernorm(Tensor input, Tensor weight, Tensor bias, float eps, Tensor? scale, bool stochastic_rounding, Tensor(a!) out, Tensor(b!) mean, Tensor(c!) istd, Tensor(d!) amax) -> (Tensor(a!), Tensor(b!), Tensor(c!), Tensor(d!));
../../habana_kernels/kernels_register.cpp:2372;       hpu;  hpu::fp8_layernorm;                                 hpu::fp8_layernorm(Tensor input, Tensor weight, Tensor bias, float eps, Tensor? scale, bool stochastic_rounding, Tensor(a!) out, Tensor(b!) mean, Tensor(c!) istd, Tensor(d!) amax) -> (Tensor(a!), Tensor(b!), Tensor(c!), Tensor(d!));
../../habana_eager/eager_custom_op_register.cpp:1715; hpu;  hpu::fp8_permute;                                   hpu::fp8_permute(Tensor input, int[] dims, Tensor(a!) out) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2383;       hpu;  hpu::fp8_permute;                                   hpu::fp8_permute(Tensor input, int[] dims, Tensor(a!) out) -> Tensor(a!);
../../habana_eager/eager_custom_op_register.cpp:1716; hpu;  hpu::fp8_repeat_v2;                                 hpu::fp8_repeat_v2(Tensor self, SymInt[] repeats) -> Tensor;
../../habana_kernels/kernels_register.cpp:2460;       hpu;  hpu::fp8_repeat_v2;                                 hpu::fp8_repeat_v2(Tensor self, SymInt[] repeats) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1717; hpu;  hpu::fp8_reshape;                                   hpu::fp8_reshape(Tensor input, int[] shape) -> Tensor;
../../habana_kernels/kernels_register.cpp:2384;       hpu;  hpu::fp8_reshape;                                   hpu::fp8_reshape(Tensor input, int[] shape) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1718; hpu;  hpu::fp8_transpose;                                 hpu::fp8_transpose(Tensor input, Tensor(a!) out) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2381;       hpu;  hpu::fp8_transpose;                                 hpu::fp8_transpose(Tensor input, Tensor(a!) out) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2254;       hpu;  hpu::group_norm;                                    hpu::group_norm(Tensor input, Tensor weight, Tensor bias, int[] normalized_shape, int64_t num_groups, double eps) -> (Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2256;       hpu;  hpu::group_norm_backward;                           hpu::group_norm_backward(Tensor grad_out,Tensor input, Tensor mean, Tensor rstd, Tensor weight, int[] normalized_shape, int64_t num_groups, bool[3] output_mask) -> (Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2208;       hpu;  hpu::habanaOptimizerAdamW;                          hpu::habanaOptimizerAdamW(Tensor[] gradient_vec, Tensor(a!)[] weight_vec, Tensor(b!)[] exp_avg_vec, Tensor(c!)[] exp_avg_sq_vec, Tensor neg_step_t, float beta1, float beta2, float epsilon, Tensor weight_decay, bool has_weight_decay) -> ();
../../habana_kernels/kernels_register.cpp:2212;       hpu;  hpu::habanaOptimizerFusedEMA;                       hpu::habanaOptimizerFusedEMA(Tensor[] model_inputs, Tensor(a!)[] updated_ema, Tensor decay) -> ();
../../habana_eager/eager_custom_op_register.cpp:1776; hpu;  hpu::habana_bernoulli;                              hpu::habana_bernoulli(Tensor seed, Tensor self) -> Tensor;
../../habana_kernels/kernels_register.cpp:2472;       hpu;  hpu::habana_bernoulli;                              hpu::habana_bernoulli(Tensor self, Tensor seed) -> Tensor;
../../habana_kernels/kernels_register.cpp:2406;       hpu;  hpu::habana_bounds_check_indices;                   hpu::habana_bounds_check_indices(Tensor(a!) indices, Tensor(b!) offsets, Tensor(c!) warning, Tensor rows_per_table, int bounds_check_mode, Tensor? weights) -> (Tensor(a!), Tensor(b!), Tensor(c!));
../../habana_kernels/kernels_register.cpp:2338;       hpu;  hpu::habana_cast_sr_mode;                           hpu::habana_cast_sr_mode(Tensor input, Scalar type, bool stochastic_rounding, int seed=0) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2397;       hpu;  hpu::habana_expand_into_jagged_permute;             hpu::habana_expand_into_jagged_permute(Tensor permute, Tensor input_offsets, Tensor output_offsets, int output_size) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1784; hpu;  hpu::habana_multinomial;                            hpu::habana_multinomial(Tensor see, Tensor self, int num_samples, bool replacement=False) -> Tensor;
../../habana_kernels/kernels_register.cpp:2480;       hpu;  hpu::habana_multinomial;                            hpu::habana_multinomial(Tensor see, Tensor self, int num_samples, bool replacement=False) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1815; hpu;  hpu::habana_native_dropout;                         hpu::habana_native_dropout(Tensor seed, Tensor input, float p, bool? train)-> (Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2488;       hpu;  hpu::habana_native_dropout;                         hpu::habana_native_dropout(Tensor seed, Tensor input, float p, bool? train)-> (Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2389;       hpu;  hpu::habana_permute_1D_sparse_data;                 hpu::habana_permute_1D_sparse_data(Tensor permute, Tensor lengths, Tensor indices, Tensor? weights=None) -> (Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2391;       hpu;  hpu::habana_permute_1D_sparse_data_without_weights; hpu::habana_permute_1D_sparse_data_without_weights(Tensor permute, Tensor lengths, Tensor indices) -> (Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2393;       hpu;  hpu::habana_permute_2D_sparse_data;                 hpu::habana_permute_2D_sparse_data(Tensor permute, Tensor lengths, Tensor indices, Tensor? weights=None) -> (Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2395;       hpu;  hpu::habana_permute_2D_sparse_data_without_weights; hpu::habana_permute_2D_sparse_data_without_weights(Tensor permute, Tensor lengths, Tensor indices) -> (Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2474;       hpu;  hpu::habana_rand;                                   hpu::habana_rand(SymInt[] size, Tensor seed, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1778; hpu;  hpu::habana_rand;                                   hpu::habana_rand(Tensor seed, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1782; hpu;  hpu::habana_randint;                                hpu::habana_randint(Tensor seed, SymInt low, SymInt high, SymInt[] size, *, ScalarType? dtype=long, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor;
../../habana_kernels/kernels_register.cpp:2478;       hpu;  hpu::habana_randint;                                hpu::habana_randint(Tensor seed, SymInt low, SymInt high, SymInt[] size, *, ScalarType? dtype=long, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor;
../../habana_kernels/kernels_register.cpp:2476;       hpu;  hpu::habana_randn;                                  hpu::habana_randn(SymInt[] size, Tensor seed, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1780; hpu;  hpu::habana_randn;                                  hpu::habana_randn(Tensor seed, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor;
../../habana_kernels/kernels_register.cpp:2387;       hpu;  hpu::habana_random_seed;                            hpu::habana_random_seed(Tensor input) -> (Tensor);
../../habana_eager/eager_custom_op_register.cpp:1811; hpu;  hpu::habana_randperm;                               hpu::habana_randperm(Tensor seed, SymInt n, *, ScalarType? dtype=long, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor;
../../habana_kernels/kernels_register.cpp:2486;       hpu;  hpu::habana_randperm;                               hpu::habana_randperm(Tensor seed, SymInt n, *, ScalarType? dtype=long, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1786; hpu;  hpu::habana_seed_generator;                         hpu::habana_seed_generator(Tensor seed, Tensor counter, int size) -> Tensor;
../../habana_kernels/kernels_register.cpp:2482;       hpu;  hpu::habana_seed_generator;                         hpu::habana_seed_generator(Tensor seed, Tensor counter, int size) -> Tensor;
../../habana_kernels/kernels_register.cpp:2399;       hpu;  hpu::habana_split_permute_cat;                      hpu::habana_split_permute_cat(Tensor input, Tensor indices, int batch_size, int num_features, int dims) -> Tensor;
../../habana_kernels/kernels_register.cpp:2336;       hpu;  hpu::identity;                                      hpu::identity(Tensor self) -> (Tensor);
../../habana_eager/eager_custom_op_register.cpp:1719; hpu;  hpu::in_place_interleave;                           hpu::in_place_interleave(Tensor self) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1720; hpu;  hpu::in_place_interleave_;                          hpu::in_place_interleave_(Tensor(a!) self) -> (Tensor(a!));
../../habana_kernels/kernels_register.cpp:2467;       hpu;  hpu::in_place_interleave_;                          hpu::in_place_interleave_(Tensor(a!) self) -> (Tensor(a!));
../../habana_kernels/kernels_register.cpp:2386;       hpu;  hpu::index_add;                                     hpu::index_add(Tensor self, int dim, Tensor index, Tensor source, *, Scalar alpha=1) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1722; hpu;  hpu::kv_reorder;                                    hpu::kv_reorder(Tensor self, Tensor start, Tensor end, Tensor beam_idx) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1724; hpu;  hpu::kv_reorder_;                                   hpu::kv_reorder_(Tensor(a!) self, Tensor start, Tensor end, Tensor beam_idx) -> (Tensor(a!));
../../habana_kernels/kernels_register.cpp:2457;       hpu;  hpu::kv_reorder_;                                   hpu::kv_reorder_(Tensor(a!) self, Tensor start, Tensor end, Tensor beam_idx) -> (Tensor(a!));
../../habana_eager/eager_custom_op_register.cpp:1726; hpu;  hpu::masked_batch_gemm;                             hpu::masked_batch_gemm(Tensor a, Tensor b, Tensor mask_a, Tensor mask_b, bool trans_a, bool trans_b) -> Tensor;
../../habana_kernels/kernels_register.cpp:2420;       hpu;  hpu::masked_batch_gemm;                             hpu::masked_batch_gemm(Tensor a, Tensor b, Tensor mask_a, Tensor mask_b, bool trans_a, bool trans_b) -> Tensor;
../../habana_kernels/kernels_register.cpp:2252;       hpu;  hpu::native_batch_norm_backward;                    hpu::native_batch_norm_backward(Tensor input, Tensor? grad_out, Tensor? weight, Tensor? mean, Tensor? invistd, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2250;       hpu;  hpu::native_batch_norm_inf;                         hpu::native_batch_norm_inf(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2248;       hpu;  hpu::native_batch_norm_training;                    hpu::native_batch_norm_training(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -> (Tensor, Tensor, Tensor, Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1728; hpu;  hpu::optimizer_adamw;                               hpu::optimizer_adamw(Tensor[] gradient_vec, Tensor(a!)[] weight_vec, Tensor(b!)[] exp_avg_vec, Tensor(c!)[] exp_avg_sq_vec, Tensor neg_step_t, float beta1, float beta2, float epsilon, Tensor weight_decay, bool has_weight_decay) -> ();
../../habana_kernels/kernels_register.cpp:2210;       hpu;  hpu::optimizer_adamw;                               hpu::optimizer_adamw(Tensor[] gradient_vec, Tensor(a!)[] weight_vec, Tensor(b!)[] exp_avg_vec, Tensor(c!)[] exp_avg_sq_vec, Tensor neg_step_t, float beta1, float beta2, float epsilon, float weight_decay) -> ();
../../habana_eager/eager_custom_op_register.cpp:1730; hpu;  hpu::optimizer_ema;                                 hpu::optimizer_ema(Tensor[] model_inputs, Tensor(a!)[] updated_ema, Tensor decay) -> ();
../../habana_eager/eager_custom_op_register.cpp:1732; hpu;  hpu::optimizer_lamb_fused_norm;                     hpu::optimizer_lamb_fused_norm(Tensor[] grad, float max_norm) -> Tensor;
../../habana_kernels/kernels_register.cpp:2214;       hpu;  hpu::optimizer_lamb_fused_norm;                     hpu::optimizer_lamb_fused_norm(Tensor[] grad, float max_norm) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1734; hpu;  hpu::optimizer_lamb_phase1;                         hpu::optimizer_lamb_phase1(Tensor[] gradients, Tensor[] weights, Tensor(a!)[] exp_avg, Tensor(b!)[] exp_avg_sq, Tensor(c!)[] out_weight_norms, Tensor(d!)[] out_adam_norms, Tensor(e!)[] out_adam_steps, Tensor clip_global_grad_norm, int grad_averaging, float beta1, float beta2, float epsilon, Tensor bias_correction1, Tensor bias_correction2, float weight_decay) -> ();
../../habana_kernels/kernels_register.cpp:2216;       hpu;  hpu::optimizer_lamb_phase1;                         hpu::optimizer_lamb_phase1(Tensor[] gradients, Tensor[] weights, Tensor(a!)[] exp_avg, Tensor(b!)[] exp_avg_sq, Tensor(c!)[] out_weight_norms, Tensor(d!)[] out_adam_norms, Tensor(e!)[] out_adam_steps, Tensor clip_global_grad_norm, int grad_averaging, float beta1, float beta2, float epsilon, Tensor bias_correction1, Tensor bias_correction2, float weight_decay) -> ();
../../habana_eager/eager_custom_op_register.cpp:1736; hpu;  hpu::optimizer_lamb_phase2;                         hpu::optimizer_lamb_phase2(Tensor(a!)[] weights, Tensor[] adam_norms, Tensor[] weight_norms, Tensor[] adam_steps, Tensor neg_step, float wd, bool use_lamb) -> ();
../../habana_kernels/kernels_register.cpp:2218;       hpu;  hpu::optimizer_lamb_phase2;                         hpu::optimizer_lamb_phase2(Tensor(a!)[] weights, Tensor[] adam_norms, Tensor[] weight_norms, Tensor[] adam_steps, Tensor neg_step, float wd, bool use_lamb) -> ();
../../habana_eager/eager_custom_op_register.cpp:1738; hpu;  hpu::optimizer_lars;                                hpu::optimizer_lars(Tensor[] params, Tensor(a!)[] grads, int[] skip_masks, float eeta, float weight_decay, float eps, Tensor lr) -> ();
../../habana_eager/eager_custom_op_register.cpp:1740; hpu;  hpu::optimizer_resource_apply_momentum;             hpu::optimizer_resource_apply_momentum(Tensor(a!)[] params_momentum_buf_list, Tensor[] dp_list, float momentum) -> ();
../../habana_kernels/kernels_register.cpp:2401;       hpu;  hpu::ragged_softmax;                                hpu::ragged_softmax(Tensor self, int dim, bool half_to_float, Tensor valid_count) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1741; hpu;  hpu::repeat_ht;                                     hpu::repeat_ht(Tensor self, Tensor result_shape) -> Tensor;
../../habana_kernels/kernels_register.cpp:2321;       hpu;  hpu::repeat_ht;                                     hpu::repeat_ht(Tensor self, Tensor result_shape) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1743; hpu;  hpu::rms_norm;                                      hpu::rms_norm(Tensor data_in, Tensor gamma, float epsilon) -> (Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2412;       hpu;  hpu::rms_norm;                                      hpu::rms_norm(Tensor data_in, Tensor gamma, float epsilon) -> (Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1745; hpu;  hpu::rms_norm_backward;                             hpu::rms_norm_backward(Tensor grad_in, Tensor data_in, Tensor gamma, Tensor inverse_rms, bool use_stages, int bwd_mode) -> (Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2414;       hpu;  hpu::rms_norm_backward;                             hpu::rms_norm_backward(Tensor grad_in, Tensor data_in, Tensor gamma, Tensor inverse_rms, bool use_stages, int bwd_mode) -> (Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1747; hpu;  hpu::rotary_pos_embedding;                          hpu::rotary_pos_embedding(Tensor input, Tensor sin, Tensor cos, Tensor? position_ids, int offset, int mode) -> Tensor;
../../habana_kernels/kernels_register.cpp:2408;       hpu;  hpu::rotary_pos_embedding;                          hpu::rotary_pos_embedding(Tensor input, Tensor sin, Tensor cos, Tensor? position_ids, int offset, int mode) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1749; hpu;  hpu::rotary_pos_embedding_backward;                 hpu::rotary_pos_embedding_backward(Tensor grad_in, Tensor sin, Tensor cos, Tensor? position_ids, int offset, int mode) -> Tensor;
../../habana_kernels/kernels_register.cpp:2410;       hpu;  hpu::rotary_pos_embedding_backward;                 hpu::rotary_pos_embedding_backward(Tensor grad_in, Tensor sin, Tensor cos, Tensor? position_ids, int offset, int mode) -> Tensor;
../../habana_kernels/kernels_register.cpp:2403;       hpu;  hpu::scaled_masked_softmax;                         hpu::scaled_masked_softmax(Tensor input, Tensor mask, float scale) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1755; hpu;  hpu::scaled_masked_triangular_softmax;              hpu::scaled_masked_triangular_softmax(Tensor self, Tensor start_end, float inv_scale_attn, int grouped_batch_size, bool use_max, int mode, ScalarType? out_dtype=None) -> Tensor;
../../habana_kernels/kernels_register.cpp:2464;       hpu;  hpu::scaled_masked_triangular_softmax;              hpu::scaled_masked_triangular_softmax(Tensor self, Tensor start_end, float inv_scale_attn, int grouped_batch_size, bool use_max, int mode, ScalarType? out_dtype=None) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1757; hpu;  hpu::scaled_triangular_softmax;                     hpu::scaled_triangular_softmax(Tensor self, float inv_scale_attn, Tensor? exp_sum_recpr=None, Tensor? max=None) -> Tensor;
../../habana_kernels/kernels_register.cpp:2450;       hpu;  hpu::scaled_triangular_softmax;                     hpu::scaled_triangular_softmax(Tensor self, float inv_scale_attn, Tensor? exp_sum_recpr=None, Tensor? max=None) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1761; hpu;  hpu::scaled_triangular_softmax_retain;              hpu::scaled_triangular_softmax_retain(Tensor self, float inv_scale_attn) -> (Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2452;       hpu;  hpu::scaled_triangular_softmax_retain;              hpu::scaled_triangular_softmax_retain(Tensor self, float inv_scale_attn) -> (Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2329;       hpu;  hpu::scatter_nd;                                    hpu::scatter_nd(Tensor input, Tensor indices, Tensor grouped_indices, Tensor update_locations, Tensor updates) -> Tensor;
../../habana_kernels/kernels_register.cpp:2327;       hpu;  hpu::scatter_nd_onnx;                               hpu::scatter_nd_onnx(Tensor input, Tensor indices, Tensor values) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1809; hpu;  hpu::sdpa_bwd;                                      hpu::sdpa_bwd(Tensor grad, Tensor q, Tensor k, Tensor v, Tensor P, Tensor? dm, float p, float scale) -> (Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2436;       hpu;  hpu::sdpa_bwd;                                      hpu::sdpa_bwd(Tensor grad, Tensor q, Tensor k, Tensor v, Tensor P, Tensor? dm, float p, float scale) -> (Tensor, Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1801; hpu;  hpu::sdpa_fwd;                                      hpu::sdpa_fwd(Tensor q, Tensor k, Tensor v, Tensor? attention_mask, float p, float scale, bool is_causal, str softmax_mode) -> (Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2428;       hpu;  hpu::sdpa_fwd;                                      hpu::sdpa_fwd(Tensor q, Tensor k, Tensor v, Tensor? attention_mask, float p, float scale, bool is_causal, str softmax_mode) -> (Tensor, Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1803; hpu;  hpu::sdpa_fwd_dropout;                              hpu::sdpa_fwd_dropout(Tensor q, Tensor k, Tensor v, Tensor? attention_mask, float p, float scale, bool is_causal, str softmax_mode) -> (Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2430;       hpu;  hpu::sdpa_fwd_dropout;                              hpu::sdpa_fwd_dropout(Tensor q, Tensor k, Tensor v, Tensor? attention_mask, float p, float scale, bool is_causal, str softmax_mode) -> (Tensor, Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1807; hpu;  hpu::sdpa_fwd_dropout_seed;                         hpu::sdpa_fwd_dropout_seed(Tensor seed, Tensor q, Tensor k, Tensor v, Tensor? attention_mask, float p, float scale, bool is_causal, str softmax_mode) -> (Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2434;       hpu;  hpu::sdpa_fwd_dropout_seed;                         hpu::sdpa_fwd_dropout_seed(Tensor seed, Tensor q, Tensor k, Tensor v, Tensor? attention_mask, float p, float scale, bool is_causal, str softmax_mode) -> (Tensor, Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1805; hpu;  hpu::sdpa_fwd_non_dropout;                          hpu::sdpa_fwd_non_dropout(Tensor q, Tensor k, Tensor v, Tensor? attention_mask, float p, float scale, bool is_causal, str softmax_mode) -> (Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2432;       hpu;  hpu::sdpa_fwd_non_dropout;                          hpu::sdpa_fwd_non_dropout(Tensor q, Tensor k, Tensor v, Tensor? attention_mask, float p, float scale, bool is_causal, str softmax_mode) -> (Tensor, Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1799; hpu;  hpu::sdpa_recomp_bwd;                               hpu::sdpa_recomp_bwd(Tensor grad, Tensor q, Tensor k, Tensor v, Tensor? attention_mask, Tensor m, Tensor linv, Tensor ? seed, bool is_causal, float p, float scale) -> (Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2448;       hpu;  hpu::sdpa_recomp_bwd;                               hpu::sdpa_recomp_bwd(Tensor grad, Tensor q, Tensor k, Tensor v, Tensor? attention_mask, Tensor m, Tensor linv, Tensor ? seed, bool is_causal, float p, float scale) -> (Tensor, Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1790; hpu;  hpu::sdpa_recomp_fwd;                               hpu::sdpa_recomp_fwd(Tensor q, Tensor k, Tensor v, Tensor? attention_mask, float p, float scale, bool is_causal, bool requires_backward, str softmax_mode) -> (Tensor, Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2439;       hpu;  hpu::sdpa_recomp_fwd;                               hpu::sdpa_recomp_fwd(Tensor q, Tensor k, Tensor v, Tensor? attention_mask, float p, float scale, bool is_causal, bool requires_backward, str softmax_mode) -> (Tensor, Tensor, Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1792; hpu;  hpu::sdpa_recomp_fwd_dropout;                       hpu::sdpa_recomp_fwd_dropout(Tensor q, Tensor k, Tensor v, Tensor? attention_mask, float p, float scale, bool is_causal, bool requires_backward, str softmax_mode) -> (Tensor, Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2441;       hpu;  hpu::sdpa_recomp_fwd_dropout;                       hpu::sdpa_recomp_fwd_dropout(Tensor q, Tensor k, Tensor v, Tensor? attention_mask, float p, float scale, bool is_causal, bool requires_backward, str softmax_mode) -> (Tensor, Tensor, Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1797; hpu;  hpu::sdpa_recomp_fwd_dropout_seed;                  hpu::sdpa_recomp_fwd_dropout_seed(Tensor seed, Tensor q, Tensor k, Tensor v, Tensor? attention_mask, float p, float scale, bool is_causal, bool requires_backward, str softmax_mode) -> (Tensor, Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2446;       hpu;  hpu::sdpa_recomp_fwd_dropout_seed;                  hpu::sdpa_recomp_fwd_dropout_seed(Tensor seed, Tensor q, Tensor k, Tensor v, Tensor? attention_mask, float p, float scale, bool is_causal, bool requires_backward, str softmax_mode) -> (Tensor, Tensor, Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1795; hpu;  hpu::sdpa_recomp_fwd_non_dropout;                   hpu::sdpa_recomp_fwd_non_dropout(Tensor q, Tensor k, Tensor v, Tensor? attention_mask, float p, float scale, bool is_causal, bool requires_backward, str softmax_mode) -> (Tensor, Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2444;       hpu;  hpu::sdpa_recomp_fwd_non_dropout;                   hpu::sdpa_recomp_fwd_non_dropout(Tensor q, Tensor k, Tensor v, Tensor? attention_mask, float p, float scale, bool is_causal, bool requires_backward, str softmax_mode) -> (Tensor, Tensor, Tensor, Tensor);
../../habana_eager/eager_custom_op_register.cpp:1771; hpu;  hpu::select_scatter;                                hpu::select_scatter(Tensor self, Tensor src, Tensor dim, Tensor index) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2303;       hpu;  hpu::select_scatter;                                hpu::select_scatter(Tensor self, Tensor src, Tensor dim, Tensor index) -> (Tensor);
../../habana_eager/eager_custom_op_register.cpp:1773; hpu;  hpu::slice_scatter;                                 hpu::slice_scatter(Tensor self, Tensor src, Tensor dim = None, Tensor? start = None, Tensor? end = None, Tensor step = None) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2305;       hpu;  hpu::slice_scatter;                                 hpu::slice_scatter(Tensor self, Tensor src, Tensor dim = None, Tensor? start = None, Tensor? end = None, Tensor step = None) -> (Tensor);
../../habana_eager/eager_custom_op_register.cpp:1759; hpu;  hpu::softmax_fp8;                                   hpu::softmax_fp8(Tensor input, int dim, Tensor? input_scale=None, Tensor? output_scale=None, Tensor? inv_attn_heads=None) -> Tensor;
../../habana_kernels/kernels_register.cpp:2466;       hpu;  hpu::softmax_fp8;                                   hpu::softmax_fp8(Tensor input, int dim, Tensor? input_scale=None, Tensor? output_scale=None, Tensor? inv_attn_heads=None) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1788; hpu;  hpu::sum_fp8;                                       hpu::sum_fp8(Tensor self, int[1]? dim=None, bool keepdim=False, ScalarType? out_dtype=None) -> Tensor;
../../habana_kernels/kernels_register.cpp:2484;       hpu;  hpu::sum_fp8;                                       hpu::sum_fp8(Tensor self, int[1]? dim=None, bool keepdim=False, ScalarType? out_dtype=None) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1762; hpu;  hpu::view;                                          hpu::view(Tensor input, Tensor shape) -> Tensor;
../../habana_eager/eager_custom_op_register.cpp:1763; hpu;  hpu::view_neg;                                      hpu::view_neg(Tensor input, Tensor shape, int[] shape) -> Tensor;
../../habana_eager/ops/copy_from.cpp:442;             hpu;  identity;                                           identity(Tensor self) -> Tensor;
../../generated/backend/hpu_op2.cpp:1065;             hpu;  index.Tensor;                                       index.Tensor(Tensor self, Tensor[] indices, bool[] advanced_indexing_dims, int[] self_permute_dims, int num_index_tensors) -> Tensor;
../../generated/backend/hpu_op2.cpp:1066;             hpu;  index.Tensor_out;                                   index.Tensor_out(Tensor self, Tensor[] indices, bool[] advanced_indexing_dims, int[] self_permute_dims, int num_index_tensors, Tensor(a!) out) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2182;       hpu;  index_put;                                          index_put(Tensor self, Tensor where_tensor, Tensor shape_tensor, Tensor value, Tensor value_upd_dim, Tensor zero_shape_tensor, bool accumulate=False) -> Tensor;
../../habana_kernels/kernels_register.cpp:2310;       hpu;  instance_norm;                                      instance_norm(Tensor input, Tensor weight, Tensor bias, float eps) -> (Tensor, Tensor, Tensor);
../../habana_eager/ops/instance_norm.cpp:98;          hpu;  instance_norm;                                      instance_norm(Tensor input, Tensor? weight, Tensor? bias, float eps) -> (Tensor, Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2312;       hpu;  instance_norm_backward;                             instance_norm_backward(Tensor input, Tensor grad_in, Tensor mean, Tensor istd, Tensor gamma) -> (Tensor, Tensor, Tensor);
../../habana_eager/ops/instance_norm.cpp:100;         hpu;  instance_norm_backward;                             instance_norm_backward(Tensor input, Tensor grad_in, Tensor mean, Tensor istd, Tensor? gamma) -> (Tensor, Tensor, Tensor);
../../generated/backend/hpu_op5.cpp:1252;             hpu;  log_normal_;                                        log_normal_(Tensor(a!) self, float mean=1, float std=2, *, Tensor seed) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2308;       hpu;  matmul_backward;                                    matmul_backward(Tensor grad_out, Tensor self, Tensor other) -> (Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2185;       hpu;  mm_t;                                               mm_t(Tensor mm, Tensor t , bool tr, bool no_tr) -> Tensor;
../../habana_kernels/kernels_register.cpp:2183;       hpu;  mul_out;                                            mul_out(Tensor self, Tensor other, Tensor(a!) out) -> Tensor(a!);
../../generated/backend/hpu_op6.cpp:1158;             hpu;  multinomial;                                        multinomial(Tensor self, int num_samples, bool replacement, Tensor seed) -> Tensor;
../../generated/backend/hpu_op6.cpp:1157;             hpu;  multinomial.out;                                    multinomial.out(Tensor self, int num_samples, bool replacement, Tensor seed,  Tensor(a!) out) -> Tensor(a!);
../../generated/backend/hpu_op0.cpp:1089;             hpu;  native_dropout;                                     native_dropout(Tensor input, float p, Tensor? seed) -> (Tensor, Tensor);
../../habana_kernels/kernels_register.cpp:2180;       hpu;  nonzero;                                            nonzero(Tensor self, Tensor? nonzero_input_shape_tensor) -> (Tensor, Tensor);
../../habana_eager/ops/nonzero.cpp:101;               hpu;  nonzero_eager;                                      nonzero_eager(Tensor self) -> (Tensor, Tensor);
../../generated/backend/hpu_op7.cpp:1024;             hpu;  normal.Tensor_Tensor;                               normal.Tensor_Tensor(Tensor mean, Tensor stddev, *, Tensor seed) -> Tensor;
../../generated/backend/hpu_op7.cpp:1022;             hpu;  normal.Tensor_float;                                normal.Tensor_float(Tensor mean, float stddev, *, Tensor seed) -> Tensor;
../../generated/backend/hpu_op7.cpp:1023;             hpu;  normal.float_Tensor;                                normal.float_Tensor(float mean, Tensor stddev, *, Tensor seed) -> Tensor;
../../generated/backend/hpu_op7.cpp:1025;             hpu;  normal.float_float;                                 normal.float_float(float mean, float std, SymInt[] size, Tensor seed, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor;
../../generated/backend/hpu_op7.cpp:1021;             hpu;  normal_;                                            normal_(Tensor(a!) self, float mean=0, float std=1, *, Tensor seed) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2222;       hpu;  optimizer_resource_apply_momentum;                  optimizer_resource_apply_momentum(Tensor(a!)[] params_momentum_buf_list, Tensor[] dp_list, float momentum) -> ();
../../habana_kernels/optimizer_kernels.cpp:1036;      hpu;  optimizer_sgd_momentum;                             optimizer_sgd_momentum(Tensor[] gradients, Tensor(a!)[] weights_in, Tensor(b!)[] momentum_in, Tensor epoch_num, Tensor(c!) learning_rate, Tensor mom, float wd, float damp, bool nesterov) -> ();
../../habana_kernels/kernels_register.cpp:2239;       hpu;  permute;                                            permute(Tensor(a) self, int[] dims) -> Tensor(a);
../../habana_kernels/kernels_register.cpp:2240;       hpu;  permute_cl;                                         permute_cl(Tensor(a) self, int[] dims) -> Tensor(a);
../../habana_kernels/kernels_register.cpp:2243;       hpu;  permute_weight;                                     permute_weight(Tensor self, int[] size) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2244;       hpu;  permuted_weight_restride;                           permuted_weight_restride(Tensor self, int[] size) -> (Tensor);
../../generated/backend/hpu_op4.cpp:961;              hpu;  poisson;                                            poisson(Tensor self, Tensor seed) -> Tensor;
../../habana_kernels/kernels_register.cpp:2188;       hpu;  prod_dim_Int;                                       prod_dim_Int(Tensor self, int dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor;
../../generated/backend/hpu_op5.cpp:1250;             hpu;  random_;                                            random_(Tensor(a!) self, Tensor seed) -> Tensor(a!);
../../generated/backend/hpu_op5.cpp:1248;             hpu;  random_.from;                                       random_.from(Tensor(a!) self, int from, int? to, Tensor seed) -> Tensor(a!);
../../generated/backend/hpu_op5.cpp:1249;             hpu;  random_.to;                                         random_.to(Tensor(a!) self, int to, Tensor seed) -> Tensor(a!);
../../generated/backend/hpu_op3.cpp:1090;             hpu;  randperm.generator;                                 randperm.generator(SymInt n, Tensor seed, ScalarType? dtype, Layout? layout, Device? device, bool? pin_memory) -> Tensor;
../../generated/backend/hpu_op3.cpp:1091;             hpu;  randperm.generator_out;                             randperm.generator_out(SymInt n, Tensor seed, Tensor(a!) out) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2190;       hpu;  randperm_out;                                       randperm_out(int n, Tensor seed, Tensor(a!) out) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2192;       hpu;  randperm_out_ds_ht;                                 randperm_out_ds_ht(Tensor ht, Tensor seed, Tensor output) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2177;       hpu;  repeat_inlv;                                        repeat_inlv(Tensor input, Tensor repeats, int dim, Tensor out_shape) -> Tensor;
../../habana_kernels/kernels_register.cpp:2178;       hpu;  repeat_inlv_ht;                                     repeat_inlv_ht(Tensor input, Tensor repeats, int dim) -> Tensor;
../../habana_kernels/kernels_register.cpp:2306;       hpu;  reshape;                                            reshape(Tensor self, int[] size) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2242;       hpu;  restride;                                           restride(Tensor(a) self, int[] dims) -> Tensor(a);
../../habana_kernels/kernels_register.cpp:2241;       hpu;  restride_cl;                                        restride_cl(Tensor(a) self, int[] dims) -> Tensor(a);
../../habana_kernels/kernels_register.cpp:2230;       hpu;  roi_align_bwd;                                      roi_align_bwd(Tensor inputs, Tensor rois, Tensor n_rois, Tensor input_shape, int sr, float ss, bool aligned) -> Tensor;
../../habana_kernels/kernels_register.cpp:2228;       hpu;  roi_align_fwd;                                      roi_align_fwd(Tensor inputs, Tensor rois, Tensor n_rois, int out_h, int out_w, int mode, int sr, float ss, bool aligned) -> Tensor;
../../generated/backend/hpu_op8.cpp:1150;             hpu;  rrelu_with_noise;                                   rrelu_with_noise(Tensor self, Tensor noise, Scalar lower, Scalar upper, bool training, Tensor seed) -> Tensor;
../../generated/backend/hpu_op8.cpp:1149;             hpu;  rrelu_with_noise.out;                               rrelu_with_noise.out(Tensor self, Tensor noise, Scalar lower, Scalar upper, bool training, Tensor seed, Tensor(a!) out) -> Tensor(a!);
../../generated/backend/hpu_op8.cpp:1151;             hpu;  rrelu_with_noise_;                                  rrelu_with_noise_(Tensor(a!) self, Tensor noise, Scalar lower, Scalar upper, bool training, Tensor seed) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2315;       hpu;  slice;                                              slice(Tensor input, Tensor shape, Tensor step,  Tensor start) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2316;       hpu;  slice_ht;                                           slice_ht(Tensor input, Tensor shape, Tensor host_tensor) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2276;       hpu;  slice_insert;                                       slice_insert(Tensor self, Tensor other, int[] params) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2278;       hpu;  slice_insert_ds;                                    slice_insert_ds(Tensor self, Tensor other, Tensor steps, Tensor start) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2280;       hpu;  slice_insert_ds_ht;                                 slice_insert_ds_ht(Tensor self, Tensor other, Tensor host_tensor) -> (Tensor);
../../habana_eager/ops/copy_from.cpp:444;             hpu;  strided_insert;                                     strided_insert(Tensor self, Tensor other, int[] stride, int offset) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2282;       hpu;  strided_insert;                                     strided_insert(Tensor self, Tensor other, int[] stride, int offset) -> (Tensor);
../../habana_eager/ops/copy_from.cpp:446;             hpu;  strided_insert_;                                    strided_insert_(Tensor(a!) self, Tensor other, int[] stride, int offset) -> (Tensor(a!));
../../habana_kernels/kernels_register.cpp:2284;       hpu;  strided_insert_cl;                                  strided_insert_cl(Tensor self, Tensor other, int[] stride, int offset) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2288;       hpu;  strided_insert_cl_ds;                               strided_insert_cl_ds(Tensor self, Tensor other, Tensor offset) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2286;       hpu;  strided_insert_ds;                                  strided_insert_ds(Tensor self, Tensor other, Tensor offset) -> (Tensor);
../../habana_eager/eager_custom_op_register.cpp:1765; hpu;  strided_insert_orig_ds;                             strided_insert_orig_ds(Tensor self, Tensor other, Tensor stride, Tensor offset) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2298;       hpu;  strided_insert_orig_ds;                             strided_insert_orig_ds(Tensor self, Tensor other, Tensor stride, Tensor offset) -> (Tensor);
../../habana_eager/eager_custom_op_register.cpp:1767; hpu;  strided_insert_orig_ds_h2d;                         strided_insert_orig_ds_h2d(Tensor self, Tensor other, Tensor stride) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2300;       hpu;  strided_insert_orig_ds_h2d;                         strided_insert_orig_ds_h2d(Tensor self, Tensor other, Tensor stride) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2262;       hpu;  strided_view;                                       strided_view(Tensor self, int[] size, int[] stride, int offset) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2266;       hpu;  strided_view_cl;                                    strided_view_cl(Tensor self, int[] size, int[] stride, int offset) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2275;       hpu;  strided_view_cl_ds;                                 strided_view_cl_ds(Tensor self, Tensor size,Tensor offset) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2267;       hpu;  strided_view_ds;                                    strided_view_ds(Tensor self, Tensor size, Tensor offset) -> (Tensor);
../../habana_eager/eager_custom_op_register.cpp:1769; hpu;  strided_view_ds_h2d;                                strided_view_ds_h2d(Tensor self, Tensor size, Tensor stride, Tensor offset) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2269;       hpu;  strided_view_ds_h2d;                                strided_view_ds_h2d(Tensor self, Tensor size, Tensor stride, Tensor offset) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2290;       hpu;  strided_view_orig_ds;                               strided_view_orig_ds(Tensor self, Tensor size, Tensor stride, Tensor offset) -> (Tensor);
../../habana_eager/eager_custom_op_register.cpp:1775; hpu;  strided_view_orig_ds_h2d;                           strided_view_orig_ds_h2d(Tensor self, Tensor size, Tensor stride) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2292;       hpu;  strided_view_orig_ds_h2d;                           strided_view_orig_ds_h2d(Tensor self, Tensor size, Tensor stride) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2264;       hpu;  strided_view_out;                                   strided_view_out(Tensor self, int[] size, int[] stride, int offset) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2271;       hpu;  strided_view_out_ds;                                strided_view_out_ds(Tensor self, Tensor size, Tensor offset) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2273;       hpu;  strided_view_out_ds_h2d;                            strided_view_out_ds_h2d(Tensor self, Tensor size, Tensor stride, Tensor offset) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2294;       hpu;  strided_view_out_orig_ds;                           strided_view_out_orig_ds(Tensor self, Tensor size, Tensor stride, Tensor offset) -> (Tensor);
../../habana_kernels/kernels_register.cpp:2296;       hpu;  strided_view_out_orig_ds_h2d;                       strided_view_out_orig_ds_h2d(Tensor self, Tensor size, Tensor stride) -> (Tensor);
../../generated/backend/hpu_op7.cpp:1020;             hpu;  topk;                                               topk(Tensor self, Tensor k, int dim=-1, bool largest=True, bool sorted=True) -> (Tensor values, Tensor indices);
../../generated/backend/hpu_op6.cpp:1159;             hpu;  topk.values;                                        topk.values(Tensor self, Tensor k, int dim=-1, bool largest=True, bool sorted=True, *, Tensor(a!) values, Tensor(b!) indices) -> (Tensor(a!) values, Tensor(b!) indices);
../../generated/backend/hpu_op5.cpp:1251;             hpu;  uniform_;                                           uniform_(Tensor(a!) self, float from=0, float to=1, *, Tensor seed) -> Tensor(a!);
../../habana_kernels/kernels_register.cpp:2236;       hpu;  unique_dim;                                         unique_dim(Tensor self, int dim, bool sorted=True, bool return_inverse=False, bool return_counts=False) -> (Tensor, Tensor);
../../generated/backend/hpu_op9.cpp:1219;             hpu;  upsample_nearest2d_backward;                        upsample_nearest2d_backward(Tensor grad_output, int[]? output_size, Tensor input_size, float? scale_h=None, float? scale_w=None) -> Tensor;
../../habana_kernels/kernels_register.cpp:2313;       hpu;  view;                                               view(Tensor input, Tensor shape) -> Tensor;
