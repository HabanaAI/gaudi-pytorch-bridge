// Autogenerated file by gen_op.py. Do not edit directly!
#include "wrap_kernels_declarations.h"

namespace habana {
TORCH_LIBRARY_IMPL(aten, AutogradHPU, m) {
  m.impl("matmul", static_cast<at::Tensor (*)(const at::Tensor &, const at::Tensor &)>(&hpu_wrap::matmul));
  m.impl("dropout", static_cast<at::Tensor (*)(const at::Tensor &, double, bool)>(&hpu_wrap::dropout));

}

}  // namespace habana

