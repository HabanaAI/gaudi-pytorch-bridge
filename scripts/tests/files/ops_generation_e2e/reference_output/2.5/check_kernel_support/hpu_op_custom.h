// Autogenerated file by gen_op.py. Do not edit directly!

#include <torch/extension.h>
#include <pybind11/stl.h>
#include <pybind11/pybind11.h>
#include <torch/csrc/jit/tensorexpr/tensorexpr_init.h>
#include <torch/csrc/jit/python/pybind_utils.h>
#include "cpu_fallback.h"

using habana_helpers::DTypeHelper;
using namespace torch::jit;


namespace habana {

static CheckNodeWithSharedLayerValidator validator_exp_fast_math("exp_fast_math", "exp_fast_math_fwd", {0}, {}, nullptr, {}, false, false, false, false);


struct shared_layer_exp_fast_math : SharedLayerOp {
bool func(torch::jit::Stack &stack, bool is_dynamic) {
  if (stack.size() == 1) {
    auto ivalue_arr = torch::jit::last(stack, 1);
    if (ivalue_arr[0].isTensor() ) {

     at::Tensor  self;
      torch::jit::pop(stack ,self);
      auto is_supported = impl(self, is_dynamic);
      return is_supported;
    }
  }
  return false;
}
private:
bool impl(const at::Tensor & self, bool is_dynamic) {
  VAL_RETURN_IF_UNSUPPORTED_DTYPE(exp_fast_math, is_dynamic, self)

  return true;
}

};





}  // namespace habana

